#!/usr/bin/env node

/**
 * Test script for Multi-Step Azure OpenAI Orchestration
 * Tests the enhanced LLMService with real MCP server integration
 */

import fetch from 'node-fetch';

const BACKEND_URL = 'http://localhost:3001/api/v1';
const TENANT_ID = 'test-tenant-001';

// Mock agent configuration
const testAgent = {
  id: 'security-analyst-001',
  name: 'Security Analyst',
  useCase: 'Security Analysis and Risk Assessment',
  description: 'AI assistant specialized in security event analysis and compliance monitoring',
  capabilities: [
    'Security event analysis',
    'Risk assessment',
    'Compliance monitoring',
    'Audit trail analysis',
    'Security reporting'
  ],
  enabledMcpServers: ['archer-grc-server'],
  systemPrompt: 'You are a security expert focused on GRC analysis and compliance.'
};

// Mock LLM configuration for testing
const testLLMConfig = {
  provider: 'azure_openai',
  model: 'gpt-4o',
  apiKey: process.env.AZURE_OPENAI_API_KEY || 'test-key',
  endpoint: process.env.AZURE_OPENAI_ENDPOINT || 'https://test.openai.azure.com',
  temperature: 0.3,
  maxTokens: 2000
};

// Mock Archer connection for testing
const testArcherConnection = {
  id: 'archer-test-001',
  name: 'Test Archer Instance',
  baseUrl: process.env.ARCHER_BASE_URL || 'https://demo.archer.com',
  username: process.env.ARCHER_USERNAME || 'test-user',
  password: process.env.ARCHER_PASSWORD || 'test-password',
  instanceId: process.env.ARCHER_INSTANCE || '710100',
  instanceName: process.env.ARCHER_INSTANCE || '710100',
  userDomainId: process.env.ARCHER_USER_DOMAIN_ID || ''
};

/**
 * Test multi-step orchestration with different query types
 */
async function testMultiStepOrchestration() {
  console.log('üöÄ Testing Multi-Step Azure OpenAI Orchestration\n');
  
  const testCases = [
    {
      name: 'Simple Tool Call Test',
      query: 'List all available Archer applications',
      expectedTools: ['get_archer_applications'],
      expectedSteps: 1
    },
    {
      name: 'Security Events Analysis Test',
      query: 'Show me security events from the last 5 days and analyze any patterns',
      expectedTools: ['get_security_events', 'generate_security_events_report'],
      expectedSteps: 2
    },
    {
      name: 'Comprehensive Audit Test',
      query: 'Perform a comprehensive security audit: get applications, recent security events, and generate a detailed report',
      expectedTools: ['get_archer_applications', 'get_security_events', 'generate_security_events_report'],
      expectedSteps: 3
    }
  ];
  
  const results = [];
  
  for (let i = 0; i < testCases.length; i++) {
    const testCase = testCases[i];
    console.log(`\nüìã Test ${i + 1}: ${testCase.name}`);
    console.log(`Query: "${testCase.query}"\n`);
    
    try {
      const result = await testLLMServiceCall(testCase.query);
      
      // Analyze results
      const analysis = analyzeTestResult(result, testCase);
      results.push({
        testCase: testCase.name,
        success: analysis.success,
        details: analysis,
        result
      });
      
      console.log(`‚úÖ Test completed: ${analysis.success ? 'PASSED' : 'FAILED'}`);
      console.log(`Tools used: [${result.toolsUsed.join(', ')}]`);
      console.log(`Processing time: ${result.processingTime}ms`);
      console.log(`Token usage: ${result.usage.totalTokens} tokens\n`);
      
    } catch (error) {
      console.error(`‚ùå Test failed with error:`, error.message);
      results.push({
        testCase: testCase.name,
        success: false,
        error: error.message
      });
    }
  }
  
  // Summary
  console.log('\nüìä TEST SUMMARY');
  console.log('='.repeat(50));
  
  const passed = results.filter(r => r.success).length;
  const total = results.length;
  
  console.log(`Total Tests: ${total}`);
  console.log(`Passed: ${passed}`);
  console.log(`Failed: ${total - passed}`);
  console.log(`Success Rate: ${Math.round((passed / total) * 100)}%\n`);
  
  // Detailed results
  results.forEach((result, index) => {
    console.log(`${index + 1}. ${result.testCase}: ${result.success ? '‚úÖ PASSED' : '‚ùå FAILED'}`);
    if (result.details) {
      console.log(`   Multi-step: ${result.details.multiStep ? 'Yes' : 'No'}`);
      console.log(`   Tools used: ${result.details.toolsUsed}`);
      console.log(`   Steps executed: ${result.details.stepsExecuted}`);
    }
    if (result.error) {
      console.log(`   Error: ${result.error}`);
    }
  });
  
  return results;
}

/**
 * Simulate calling the enhanced LLMService
 */
async function testLLMServiceCall(query) {
  const startTime = Date.now();
  
  // This would normally be handled by the LLMService.processMessage() method
  // For testing, we'll simulate the multi-step process by calling the backend directly
  
  console.log('üîÑ Simulating multi-step orchestration...');
  
  // Step 1: Get available tools
  const toolsResponse = await fetch(`${BACKEND_URL}/mcp/tools`, {
    method: 'GET',
    headers: {
      'Content-Type': 'application/json',
      'x-tenant-id': TENANT_ID
    }
  });
  
  if (!toolsResponse.ok) {
    throw new Error(`Failed to get tools: ${toolsResponse.status}`);
  }
  
  const toolsData = await toolsResponse.json();
  const availableTools = toolsData.tools || [];
  
  console.log(`üì° Available MCP tools: ${availableTools.length}`);
  
  // Step 2: Simulate Azure OpenAI deciding which tools to call
  // (In real implementation, this would be handled by Azure OpenAI function calling)
  const toolsToCall = simulateAzureOpenAIDecision(query, availableTools);
  
  console.log(`ü§ñ Simulated Azure OpenAI decision: ${toolsToCall.length} tools to call`);
  
  const toolResults = [];
  const toolsUsed = [];
  
  // Step 3: Execute tools sequentially (multi-step orchestration)
  for (let step = 0; step < toolsToCall.length; step++) {
    const tool = toolsToCall[step];
    console.log(`üìû Step ${step + 1}: Calling ${tool.name}...`);
    
    try {
      const toolResponse = await fetch(`${BACKEND_URL}/mcp/call`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'X-Tenant-ID': TENANT_ID
        },
        body: JSON.stringify({
          toolName: tool.name,
          arguments: tool.arguments,
          connectionId: testArcherConnection.id,
          tenantId: TENANT_ID,
          agentId: testAgent.id,
          enabledMcpServers: testAgent.enabledMcpServers,
          credentials: testArcherConnection
        })
      });
      
      if (!toolResponse.ok) {
        const errorData = await toolResponse.json().catch(() => ({ error: 'Unknown error' }));
        console.log(`‚ö†Ô∏è  Tool ${tool.name} failed: ${errorData.error || toolResponse.statusText}`);
        continue;
      }
      
      const result = await toolResponse.json();
      toolResults.push(result);
      toolsUsed.push(tool.name);
      
      console.log(`‚úÖ Step ${step + 1} completed: ${tool.name}`);
      
    } catch (error) {
      console.log(`‚ùå Step ${step + 1} failed: ${error.message}`);
    }
  }
  
  // Step 4: Simulate final response generation
  const processingTime = Date.now() - startTime;
  const tokenUsage = {
    promptTokens: toolsToCall.length * 50,
    completionTokens: toolResults.length * 100,
    totalTokens: (toolsToCall.length * 50) + (toolResults.length * 100)
  };
  
  return {
    content: `Multi-step orchestration completed. Executed ${toolsUsed.length} tools successfully.`,
    usage: tokenUsage,
    model: testLLMConfig.model,
    finishReason: 'stop',
    toolsUsed,
    toolResults,
    processingTime,
    orchestrationSteps: toolsToCall.length,
    successfulSteps: toolResults.length
  };
}

/**
 * Simulate Azure OpenAI's decision making for tool calls
 * (In real implementation, this is handled by Azure OpenAI function calling)
 */
function simulateAzureOpenAIDecision(query, availableTools) {
  const toolsToCall = [];
  
  // Simple keyword-based tool selection for testing
  if (query.toLowerCase().includes('applications')) {
    toolsToCall.push({
      name: 'get_archer_applications',
      arguments: { tenant_id: TENANT_ID }
    });
  }
  
  if (query.toLowerCase().includes('security events') || query.toLowerCase().includes('security audit')) {
    toolsToCall.push({
      name: 'get_security_events',
      arguments: {
        tenant_id: TENANT_ID,
        timeRange: '5d',
        eventType: 'all events'
      }
    });
  }
  
  if (query.toLowerCase().includes('report') || query.toLowerCase().includes('analyze') || query.toLowerCase().includes('audit')) {
    // Only add report generation if we're also getting security events
    if (toolsToCall.some(t => t.name === 'get_security_events')) {
      toolsToCall.push({
        name: 'generate_security_events_report',
        arguments: {
          tenant_id: TENANT_ID,
          timeRange: '5d',
          eventType: 'all events',
          maxEvents: 100
        }
      });
    }
  }
  
  return toolsToCall;
}

/**
 * Analyze test results
 */
function analyzeTestResult(result, testCase) {
  const analysis = {
    success: false,
    multiStep: false,
    toolsUsed: result.toolsUsed.length,
    stepsExecuted: result.orchestrationSteps || 0,
    expectedTools: testCase.expectedTools,
    expectedSteps: testCase.expectedSteps
  };
  
  // Check if it's multi-step
  analysis.multiStep = result.orchestrationSteps > 1;
  
  // Check if expected tools were called
  const toolsMatch = testCase.expectedTools.every(tool => 
    result.toolsUsed.includes(tool)
  );
  
  // Check if expected number of steps were executed
  const stepsMatch = result.orchestrationSteps >= testCase.expectedSteps;
  
  // Success criteria
  analysis.success = toolsMatch && stepsMatch && result.successfulSteps > 0;
  
  return analysis;
}

/**
 * Main test execution
 */
async function main() {
  try {
    console.log('üß™ Multi-Step Orchestration Test Suite');
    console.log('=====================================\n');
    
    console.log('Configuration:');
    console.log(`Backend URL: ${BACKEND_URL}`);
    console.log(`Tenant ID: ${TENANT_ID}`);
    console.log(`Agent: ${testAgent.name}`);
    console.log(`LLM Model: ${testLLMConfig.model}\n`);
    
    const results = await testMultiStepOrchestration();
    
    console.log('\nüéØ Multi-step orchestration testing completed!');
    
    // Return results for further analysis
    process.exit(results.every(r => r.success) ? 0 : 1);
    
  } catch (error) {
    console.error('üí• Test suite failed:', error);
    process.exit(1);
  }
}

// Run tests
main().catch(console.error);